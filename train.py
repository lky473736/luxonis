# ìˆ˜ì •ëœ í†µí•© í´ë” êµ¬ì¡°ìš© YOLOv8 í•™ìŠµ ì‹œìŠ¤í…œ (ì—ëŸ¬ í•´ê²°)
import os
import yaml
import cv2
import numpy as np
from pathlib import Path
import json
import shutil
from ultralytics import YOLO
import matplotlib.pyplot as plt
from PIL import Image
import glob
import random

class FixedUnifiedYOLOTrainer:
    def __init__(self, dataset_dir="yolo_dataset"):
        self.dataset_dir = Path(dataset_dir)
        self.images_dir = self.dataset_dir / "images"
        self.labels_dir = self.dataset_dir / "labels"
        
        # ë°ì´í„°ì…‹ êµ¬ì¡° ìƒì„±
        for split in ['train', 'val', 'test']:
            (self.images_dir / split).mkdir(parents=True, exist_ok=True)
            (self.labels_dir / split).mkdir(parents=True, exist_ok=True)
        
        print("ìˆ˜ì •ëœ YOLOv8 í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
        
    def prepare_dataset_from_unified_folders(self, data_dir="data", target_dir="target", 
                                           train_ratio=0.8, val_ratio=0.15):
        """í†µí•© í´ë” êµ¬ì¡°ì—ì„œ YOLO ë°ì´í„°ì…‹ ì¤€ë¹„ (ì—ëŸ¬ ìˆ˜ì •)"""
        print("í†µí•© í´ë” êµ¬ì¡°ì—ì„œ YOLO ë°ì´í„°ì…‹ ì¤€ë¹„ ì¤‘...")
        
        data_path = Path(data_dir)
        target_path = Path(target_dir)
        
        if not data_path.exists() or not target_path.exists():
            print(f"data ë˜ëŠ” target í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
            print(f"data: {data_path.exists()}, target: {target_path.exists()}")
            return False
        
        # 1. í¬ë¡­ëœ í‘œì§€íŒ ì´ë¯¸ì§€ ìˆ˜ì§‘ (positive samplesë§Œ ì‚¬ìš©)
        print("í¬ë¡­ëœ í‘œì§€íŒ ì´ë¯¸ì§€ ìˆ˜ì§‘ ì¤‘...")
        target_images = list(target_path.glob("*.jpg")) + list(target_path.glob("*.png"))
        print(f"í¬ë¡­ëœ í‘œì§€íŒ ì´ë¯¸ì§€: {len(target_images)}ê°œ")
        
        if len(target_images) == 0:
            print("í¬ë¡­ëœ í‘œì§€íŒ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!")
            return False
        
        # 2. ì´ë¯¸ì§€ í•„í„°ë§ (ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€ ì œì™¸)
        valid_images = []
        for img_path in target_images:
            try:
                img = cv2.imread(str(img_path))
                if img is not None:
                    h, w = img.shape[:2]
                    if h >= 32 and w >= 32:  # ìµœì†Œ í¬ê¸° ì²´í¬
                        valid_images.append(img_path)
            except:
                continue
        
        print(f"ìœ íš¨í•œ ì´ë¯¸ì§€: {len(valid_images)}ê°œ")
        
        if len(valid_images) < 10:
            print("ìœ íš¨í•œ ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤! (ìµœì†Œ 10ê°œ í•„ìš”)")
            return False
        
        # 3. ë°ì´í„°ì…‹ ë¶„í• 
        random.shuffle(valid_images)
        n_train = int(len(valid_images) * train_ratio)
        n_val = int(len(valid_images) * val_ratio)
        
        train_images = valid_images[:n_train]
        val_images = valid_images[n_train:n_train+n_val]
        test_images = valid_images[n_train+n_val:]
        
        print(f"ë°ì´í„° ë¶„í• : Train {len(train_images)}, Val {len(val_images)}, Test {len(test_images)}")
        
        # 4. ê° ë¶„í• ì— ë°ì´í„° ë³µì‚¬ ë° ë¼ë²¨ ìƒì„±
        for split, images in [('train', train_images), ('val', val_images), ('test', test_images)]:
            if len(images) == 0:
                continue
                
            print(f"\n{split} ë°ì´í„°ì…‹ ì²˜ë¦¬ ì¤‘... ({len(images)}ê°œ)")
            
            for i, img_path in enumerate(images):
                try:
                    # ì´ë¯¸ì§€ ë¡œë“œ
                    img = cv2.imread(str(img_path))
                    if img is None:
                        continue
                    
                    h, w = img.shape[:2]
                    
                    # ì´ë¯¸ì§€ í¬ê¸° ì •ê·œí™” (640x640ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ)
                    target_size = 640
                    scale = min(target_size / w, target_size / h)
                    new_w = int(w * scale)
                    new_h = int(h * scale)
                    
                    # ë¦¬ì‚¬ì´ì¦ˆ
                    img_resized = cv2.resize(img, (new_w, new_h))
                    
                    # íŒ¨ë”© ì¶”ê°€ (ì •ì‚¬ê°í˜•ìœ¼ë¡œ ë§Œë“¤ê¸°)
                    pad_w = (target_size - new_w) // 2
                    pad_h = (target_size - new_h) // 2
                    
                    img_padded = cv2.copyMakeBorder(
                        img_resized, pad_h, target_size - new_h - pad_h, 
                        pad_w, target_size - new_w - pad_w, 
                        cv2.BORDER_CONSTANT, value=(114, 114, 114)
                    )
                    
                    # ìƒˆ íŒŒì¼ëª… ìƒì„±
                    new_img_name = f"sign_{split}_{i:04d}.jpg"
                    new_img_path = self.images_dir / split / new_img_name
                    cv2.imwrite(str(new_img_path), img_padded)
                    
                    # ë¼ë²¨ íŒŒì¼ ìƒì„± (ì •ê·œí™”ëœ ì¢Œí‘œ)
                    # íŒ¨ë”©ì„ ê³ ë ¤í•œ ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
                    bbox_x_center = (pad_w + new_w / 2) / target_size
                    bbox_y_center = (pad_h + new_h / 2) / target_size
                    bbox_width = new_w / target_size
                    bbox_height = new_h / target_size
                    
                    # ì¢Œí‘œ í´ë¦¬í•‘ (0-1 ë²”ìœ„)
                    bbox_x_center = max(0, min(1, bbox_x_center))
                    bbox_y_center = max(0, min(1, bbox_y_center))
                    bbox_width = max(0, min(1, bbox_width))
                    bbox_height = max(0, min(1, bbox_height))
                    
                    label_content = f"0 {bbox_x_center:.6f} {bbox_y_center:.6f} {bbox_width:.6f} {bbox_height:.6f}\n"
                    
                    label_path = self.labels_dir / split / f"sign_{split}_{i:04d}.txt"
                    with open(label_path, 'w') as f:
                        f.write(label_content)
                    
                    if (i + 1) % 20 == 0:
                        print(f"  {i + 1}/{len(images)} ì™„ë£Œ")
                        
                except Exception as e:
                    print(f"  ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜ {img_path}: {e}")
                    continue
        
        # 5. ìµœì¢… ê²€ì¦
        total_train = len(list((self.images_dir / 'train').glob('*.jpg')))
        total_val = len(list((self.images_dir / 'val').glob('*.jpg')))
        total_test = len(list((self.images_dir / 'test').glob('*.jpg')))
        
        print(f"\nâœ… ë°ì´í„°ì…‹ ì¤€ë¹„ ì™„ë£Œ!")
        print(f"ìµœì¢… ë°ì´í„°: Train {total_train}, Val {total_val}, Test {total_test}")
        
        if total_train < 5 or total_val < 2:
            print("âš ï¸ ê²½ê³ : ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ì„±ëŠ¥ì´ ì¢‹ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        return True
    
    def create_yaml_config(self):
        """YOLO í•™ìŠµìš© YAML ì„¤ì • íŒŒì¼ ìƒì„±"""
        config = {
            'path': str(self.dataset_dir.absolute()),
            'train': 'images/train',
            'val': 'images/val',
            'test': 'images/test',
            'nc': 1,  # number of classes
            'names': ['school_zone_sign']
        }
        
        yaml_path = self.dataset_dir / "school_zone_config.yaml"
        with open(yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
        print(f"YAML ì„¤ì • íŒŒì¼ ìƒì„±: {yaml_path}")
        return yaml_path
    
    def train_model(self, yaml_path, model_size='n', epochs=50, imgsz=640, batch_size=8):
        """YOLOv8 ëª¨ë¸ í•™ìŠµ (ì—ëŸ¬ ë°©ì§€ ì„¤ì •)"""
        print(f"\nYOLOv8{model_size} ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
        print(f"Epochs: {epochs}, Image size: {imgsz}, Batch size: {batch_size}")
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        device = 'cpu'  # ì•ˆì •ì„±ì„ ìœ„í•´ CPU ê°•ì œ ì‚¬ìš©
        print(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        model = YOLO(f'yolov8{model_size}.pt')
        
        # ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•œ ì•ˆì „í•œ í•™ìŠµ ì„¤ì •
        try:
            results = model.train(
                data=str(yaml_path),
                epochs=epochs,
                imgsz=imgsz,
                batch=batch_size,
                name='school_zone_detector_fixed',
                project='runs/detect',
                save=True,
                patience=20,  # Early stopping
                device=device,
                workers=0,      # ë©€í‹°í”„ë¡œì„¸ì‹± ë¹„í™œì„±í™”
                augment=False,  # ì¦ê°• ë¹„í™œì„±í™” (albumentations ì—ëŸ¬ ë°©ì§€)
                mixup=0.0,      # Mixup ë¹„í™œì„±í™”
                copy_paste=0.0, # Copy-paste ë¹„í™œì„±í™”
                cache=False,    # ìºì‹œ ë¹„í™œì„±í™”
                amp=False,      # AMP ë¹„í™œì„±í™” (CPUì—ì„œëŠ” ë¶ˆí•„ìš”)
                verbose=True,
                plots=True,
                val=True
            )
            
            print("âœ… í•™ìŠµ ì™„ë£Œ!")
            return model, results
            
        except Exception as e:
            print(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("ğŸ”§ ë” ì•ˆì „í•œ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„...")
            
            # ë” ì•ˆì „í•œ ì„¤ì •ìœ¼ë¡œ ì¬ì‹œë„
            try:
                results = model.train(
                    data=str(yaml_path),
                    epochs=min(epochs, 30),  # ì—í¬í¬ ì¤„ì´ê¸°
                    imgsz=320,               # ì´ë¯¸ì§€ í¬ê¸° ì¤„ì´ê¸°
                    batch=4,                 # ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
                    name='school_zone_detector_safe',
                    project='runs/detect',
                    save=True,
                    patience=10,
                    device='cpu',
                    workers=0,
                    augment=False,
                    cache=False,
                    amp=False,
                    verbose=False,  # ë¡œê·¸ ì¤„ì´ê¸°
                    plots=False
                )
                
                print("âœ… ì•ˆì „ ëª¨ë“œ í•™ìŠµ ì™„ë£Œ!")
                return model, results
                
            except Exception as e2:
                print(f"âŒ ì•ˆì „ ëª¨ë“œë„ ì‹¤íŒ¨: {e2}")
                return None, None
    
    def validate_model(self, model_path, yaml_path):
        """ëª¨ë¸ ê²€ì¦"""
        try:
            print("ëª¨ë¸ ê²€ì¦ ì¤‘...")
            model = YOLO(model_path)
            
            # ê²€ì¦ ì‹¤í–‰
            metrics = model.val(data=str(yaml_path), device='cpu', workers=0)
            
            print(f"âœ… ê²€ì¦ ì™„ë£Œ!")
            if hasattr(metrics, 'box'):
                print(f"mAP50: {metrics.box.map50:.3f}")
                print(f"mAP50-95: {metrics.box.map:.3f}")
                print(f"Precision: {metrics.box.mp:.3f}")
                print(f"Recall: {metrics.box.mr:.3f}")
            
            return metrics
            
        except Exception as e:
            print(f"âŒ ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
            return None
    
    def export_model(self, model_path, formats=['onnx']):
        """ëª¨ë¸ì„ ë‹¤ë¥¸ í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
        try:
            model = YOLO(model_path)
            
            for format_type in formats:
                print(f"ëª¨ë¸ì„ {format_type} í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ëŠ” ì¤‘...")
                try:
                    model.export(format=format_type, imgsz=640, device='cpu')
                    print(f"âœ… {format_type} ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì™„ë£Œ!")
                except Exception as e:
                    print(f"âŒ {format_type} ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}")
                    
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë‚´ë³´ë‚´ê¸° ì˜¤ë¥˜: {e}")
    
    def test_model_quick(self, model_path, test_dir, num_samples=3):
        """ë¹ ë¥¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
        try:
            print("ë¹ ë¥¸ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            model = YOLO(model_path)
            test_path = Path(test_dir)
            
            if not test_path.exists():
                print(f"í…ŒìŠ¤íŠ¸ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {test_dir}")
                return
            
            # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë“¤ ê°€ì ¸ì˜¤ê¸°
            test_images = list(test_path.glob("*.jpg")) + list(test_path.glob("*.png"))
            if len(test_images) == 0:
                print("í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!")
                return
            
            # ëœë¤í•˜ê²Œ ìƒ˜í”Œ ì„ íƒ
            sample_images = random.sample(test_images, min(num_samples, len(test_images)))
            
            detection_count = 0
            
            for i, img_path in enumerate(sample_images):
                print(f"í…ŒìŠ¤íŠ¸ {i+1}/{len(sample_images)}: {img_path.name}")
                
                try:
                    # ì¶”ë¡ 
                    results = model(str(img_path), conf=0.3, device='cpu', verbose=False)
                    
                    # ê²°ê³¼ í™•ì¸
                    if results[0].boxes is not None and len(results[0].boxes) > 0:
                        for box in results[0].boxes:
                            conf = box.conf[0].cpu().numpy()
                            print(f"  âœ… í‘œì§€íŒ íƒì§€ë¨! ì‹ ë¢°ë„: {conf:.3f}")
                            detection_count += 1
                    else:
                        print("  âŒ í‘œì§€íŒ íƒì§€ë˜ì§€ ì•ŠìŒ")
                        
                except Exception as e:
                    print(f"  âŒ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            
            print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼: {detection_count}ê°œ íƒì§€")
            
        except Exception as e:
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")

def main_training():
    """ìˆ˜ì •ëœ í•™ìŠµ ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸš¸ ìˆ˜ì •ëœ YOLOv8 ì–´ë¦°ì´ë³´í˜¸êµ¬ì—­ í‘œì§€íŒ í•™ìŠµ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    # ì„¤ì •
    trainer = FixedUnifiedYOLOTrainer("yolo_dataset")
    
    # ë°ì´í„° ê²½ë¡œ ì…ë ¥
    data_dir = input("data í´ë” ê²½ë¡œ (Enter = data): ").strip()
    if not data_dir:
        data_dir = "data"
    
    target_dir = input("target í´ë” ê²½ë¡œ (Enter = target): ").strip()
    if not target_dir:
        target_dir = "target"
    
    # í•™ìŠµ ì„¤ì • (ì•ˆì „í•œ ê¸°ë³¸ê°’)
    model_size = input("YOLOv8 ëª¨ë¸ í¬ê¸° (n/s, Enter = n): ").strip()
    if not model_size or model_size not in ['n', 's', 'm', 'l', 'x']:
        model_size = 'n'
    
    epochs = input("í•™ìŠµ ì—í¬í¬ ìˆ˜ (Enter = 50): ").strip()
    try:
        epochs = int(epochs) if epochs else 50
        epochs = min(epochs, 100)  # ìµœëŒ€ 100ìœ¼ë¡œ ì œí•œ
    except:
        epochs = 50
    
    batch_size = input("ë°°ì¹˜ í¬ê¸° (Enter = 8): ").strip()
    try:
        batch_size = int(batch_size) if batch_size else 8
        batch_size = min(batch_size, 16)  # ìµœëŒ€ 16ìœ¼ë¡œ ì œí•œ
    except:
        batch_size = 8
    
    print(f"\nğŸ”§ í•™ìŠµ ì„¤ì •:")
    print(f"  ëª¨ë¸: YOLOv8{model_size}")
    print(f"  ì—í¬í¬: {epochs}")
    print(f"  ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"  ë””ë°”ì´ìŠ¤: CPU (ì•ˆì •ì„±)")
    
    # ë°ì´í„°ì…‹ ì¤€ë¹„
    print("\n" + "="*50)
    success = trainer.prepare_dataset_from_unified_folders(data_dir, target_dir)
    if not success:
        print("âŒ ë°ì´í„°ì…‹ ì¤€ë¹„ ì‹¤íŒ¨!")
        return
    
    # YAML ì„¤ì • íŒŒì¼ ìƒì„±
    yaml_path = trainer.create_yaml_config()
    
    # ëª¨ë¸ í•™ìŠµ
    print("\n" + "="*50)
    model, results = trainer.train_model(yaml_path, model_size, epochs, batch_size=batch_size)
    
    if model is None:
        print("âŒ í•™ìŠµ ì‹¤íŒ¨!")
        return
    
    # ìµœì  ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°
    best_model_paths = list(Path('runs/detect').glob('*/weights/best.pt'))
    if best_model_paths:
        best_model_path = str(sorted(best_model_paths)[-1])  # ê°€ì¥ ìµœê·¼ ê²ƒ
        print(f"âœ… ìµœì  ëª¨ë¸: {best_model_path}")
        
        # ëª¨ë¸ ê²€ì¦
        print("\n" + "="*50)
        trainer.validate_model(best_model_path, yaml_path)
        
        # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
        print("\n" + "="*50)
        trainer.test_model_quick(best_model_path, target_dir, 3)
        
        # ONNX ë‚´ë³´ë‚´ê¸°
        print("\n" + "="*50)
        trainer.export_model(best_model_path, ['onnx'])
        
        print(f"\n" + "="*50)
        print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {best_model_path}")
        print("ğŸ¥ ì‹¤ì‹œê°„ íƒì§€ë¥¼ ìœ„í•´ ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”:")
        print(f"python oak_realtime_detector.py --model {best_model_path}")
    else:
        print("âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    print("í•„ìš”í•œ íŒ¨í‚¤ì§€:")
    print("pip install ultralytics opencv-python")
    print("pip install 'albumentations>=1.4.0'")
    print()
    main_training()ã…